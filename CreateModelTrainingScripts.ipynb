{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "261b20b6",
   "metadata": {},
   "source": [
    "First load some utility modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2df7701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemutils.io import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5647937",
   "metadata": {},
   "source": [
    "Next we define the bulk of the script that we are going to modify for each training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8133fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script_text(dp, model_params, gen_model_weights, gen_model_params, epochs= 2000):\n",
    "    return f'''\n",
    "\n",
    "#load some packages in\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "from numba import njit\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from stemutils.io import Path\n",
    "import hyperspy.api as hs\n",
    "import concurrent.futures\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import lru_cache\n",
    "from stemseg.processing_funcs import *\n",
    "\n",
    "#set some variables\n",
    "print('Using TensorFlow v%s' % tf.__version__)\n",
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "#define some functions\n",
    "\n",
    "###################################################\n",
    "########### Data Preprocessing ####################\n",
    "###################################################\n",
    "\n",
    "def batch_resize(d, bs=512):\n",
    "    if len(d.shape) == 4:\n",
    "        flat_d = flatten_nav(d)\n",
    "    else:\n",
    "        flat_d = d\n",
    "    n_batches = int(np.ceil(flat_d.shape[0]//bs))\n",
    "    batches = [flat_d[i*bs:(i+1)*bs] for i in range(n_batches+1)]\n",
    "    if len(batches[-1])==0:\n",
    "        batches.pop(-1)\n",
    "    print(len(batches[-1]))\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as exe:\n",
    "        res = [exe.submit(resize, batch, (batch.shape[0],128,128)) for batch in batches]\n",
    "    r_batches = [f.result() for f in res]\n",
    "    return np.concatenate(r_batches, axis = 0).reshape((d.shape[0],128,128))\n",
    "\n",
    "def data_manip(d, bs = 512):\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    print('resized')\n",
    "    d = d.astype('float32')\n",
    "    for i in range(d.shape[0]):\n",
    "        d_max = np.max(d[i])\n",
    "        d[i] = d[i]/d_max\n",
    "    d = batch_resize(d, bs)\n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "def data_manip_lowq(d, central_box = 128):\n",
    "    pxc, pyc = d.shape[1]//2, d.shape[2]//2 \n",
    "    pxl, pxu = pxc - central_box//2, pxc + central_box//2 \n",
    "    pyl, pyu = pyc - central_box//2, pyc + central_box//2 \n",
    "\n",
    "    d = d[:, pxl:pxu, pyl:pyu]\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    print('resized')\n",
    "    d = d.astype('float32')\n",
    "    for i in range(d.shape[0]):\n",
    "        d_max = np.max(d[i])\n",
    "        d[i] = d[i]/d_max\n",
    "\n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "def flatten_nav(sig):\n",
    "    shape = [sig.shape[0]*sig.shape[1]]\n",
    "    for i in sig.shape[2:]:\n",
    "        shape.append(i)\n",
    "    return sig.reshape(shape)\n",
    "\n",
    "\n",
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, image_filenames,  batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "\n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        out_img = np.asarray([np.load(file_name)[:,:,None] for file_name in batch_x])\n",
    "        return out_img, out_img\n",
    "        #return batch_x, batch_y\n",
    "\n",
    "\n",
    "class Array_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, images,  batch_size, target = 'same') :\n",
    "        self.images = images\n",
    "        self.batch_size = batch_size\n",
    "        if target == 'same':\n",
    "            self.target = images\n",
    "        else:\n",
    "            self.target = target\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "\n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        out_img = self.images[idx * self.batch_size : (idx+1) * self.batch_size, :,:,None]\n",
    "        out_targ = self.target[idx * self.batch_size : (idx+1) * self.batch_size, :,:,None]\n",
    "        return out_img, out_targ\n",
    "        #return batch_x, batch_y\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def create_vae_model(hparams):\n",
    "\n",
    "    n_img = 128\n",
    "    latent_dim = hparams['LAT']\n",
    "    beta = hparams['B']\n",
    "\n",
    "    image_input = keras.Input(shape=(n_img, n_img,1), name = 'enc_input')\n",
    "    x = layers.Conv2D(hparams['KN1'],5, strides = 2, activation='relu',padding='same', input_shape=image_input.shape, name = 'enc_conv1')(image_input)\n",
    "    x = layers.Conv2D(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv2')(x)\n",
    "    x = layers.Conv2D(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv3')(x)\n",
    "    x = layers.Conv2D(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv4')(x)\n",
    "    x = layers.Conv2D(hparams['KN5'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv5')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hparams['D1'], activation='relu', name = 'enc_d1')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d2_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d3_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d4_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d5_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d6_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d7_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d8_t')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean_t\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var_t\")(x)\n",
    "    z_output = Sampling()([z_mean, z_log_var])\n",
    "    encoder_VAE = keras.Model(image_input, [z_mean, z_log_var, z_output])\n",
    "\n",
    "    z_input = keras.Input(shape=(latent_dim,), name = 'dec_input_t')\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d1_t')(z_input)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d2')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d3')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d4')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d5')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d6')(x)\n",
    "    x = layers.Dense(hparams['D1'], activation=\"relu\", name = 'dec_d7')(x)\n",
    "    x = layers.Dense(4*4*hparams['KN5'], activation=\"relu\", name = 'dec_d8')(x)\n",
    "    x = layers.Reshape((4, 4,hparams['KN5']))(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv2')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv3')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN1'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv4')(x)\n",
    "    image_output = layers.Conv2DTranspose(1,5, strides = 2, activation='sigmoid',padding='same', name = 'dec_conv5')(x)\n",
    "    #image_output = layers.Conv2DTranspose(16,3, strides = 2, activation='sigmoid',padding='same')\n",
    "    #image_output = layers.Reshape((n_img, n_img,1))(x)\n",
    "    decoder_VAE = keras.Model(z_input, image_output)\n",
    "\n",
    "    # VAE class\n",
    "    class VAE(keras.Model):\n",
    "        # constructor\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super(VAE, self).__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "\n",
    "        # customise train_step() to implement the loss \n",
    "        def train_step(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            with tf.GradientTape() as tape:\n",
    "                # encoding\n",
    "                z_mean, z_log_var, z = self.encoder(x)\n",
    "                # decoding\n",
    "                x_prime = self.decoder(z)\n",
    "                # reconstruction error by binary crossentropy loss\n",
    "                reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * n_img * n_img\n",
    "                # KL divergence\n",
    "                kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "                # loss = reconstruction error + KL divergence\n",
    "                loss = reconstruction_loss + beta* kl_loss\n",
    "            # apply gradient\n",
    "            grads = tape.gradient(loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            # return loss for metrics log\n",
    "            return {'{\"loss\": loss}'}\n",
    "\n",
    "\n",
    "        def call(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            # encoding\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            # decoding\n",
    "            x_prime = self.decoder(z)\n",
    "            return x_prime\n",
    "    # build the VAE\n",
    "    vae_model = VAE(encoder_VAE, decoder_VAE)\n",
    "\n",
    "    # compile the VAE\n",
    "    vae_model.compile(optimizer=keras.optimizers.Adam(learning_rate=hparams['LR']),loss=custom_loss)\n",
    "    vae_model.build((1,128,128,1))\n",
    "\n",
    "    return vae_model\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(x,y):\n",
    "    n_img = 128\n",
    "    return tf.reduce_mean(keras.losses.binary_crossentropy(x, y)) * n_img * n_img\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "general_model_path = Path(\"{gen_model_weights}\")\n",
    "general_model_params = {gen_model_params}\n",
    "\n",
    "gen_model = create_vae_model(general_model_params)\n",
    "gen_model.load_weights(general_model_path)\n",
    "\n",
    "def transfer_layer_weights(old_model, new_model, enc_layer_list, dec_layer_list):\n",
    "    for l in enc_layer_list:\n",
    "        w = old_model.get_layer(index = 0).get_layer(index=l).get_weights()\n",
    "        new_model.get_layer(index = 0).get_layer(index=l).set_weights(w)\n",
    "\n",
    "    for l in dec_layer_list:\n",
    "        w = old_model.get_layer(index = 1).get_layer(index=l).get_weights()\n",
    "        new_model.get_layer(index = 1).get_layer(index=l).set_weights(w)\n",
    "    return new_model\n",
    "\n",
    "enc_layer_list = list(range(12))\n",
    "\n",
    "dec_layer_list = list(range(4,14))\n",
    "\n",
    "\n",
    "dp = Path(\"{dp}\")\n",
    "mp = dp.redirect('FullModel')\n",
    "if not mp.exists():\n",
    "    mp.mkdir()\n",
    "print(mp)\n",
    "\n",
    "### Load in the Data\n",
    "\n",
    "sample = ProcessedSample(dp, 'Test')\n",
    "\n",
    "### Create a dictionary to hold some useful information\n",
    "\n",
    "info = {'{}'}\n",
    "\n",
    "nds = flatten_nav(sample.raw_data.data)\n",
    "\n",
    "nds.shape\n",
    "\n",
    "ds = hs.load(dp)\n",
    "\n",
    "sx, sy = ds.data.shape[2:]\n",
    "\n",
    "from skimage.measure import shannon_entropy\n",
    "\n",
    "entropy = np.zeros((sample.raw_data.data.shape[0:2]))\n",
    "\n",
    "for i in range(ds.data.shape[0]):\n",
    "    print(i)\n",
    "    for j in range(ds.data.shape[1]):\n",
    "        entropy[i,j] = shannon_entropy(ds.data[i,j,sx//2-128:sx//2+128, sy//2-128:sy//2+128])\n",
    "\n",
    "data_patterns = flatten_nav(ds.data)\n",
    "\n",
    "entr = flatten_nav(entropy**10)\n",
    "\n",
    "sl_pdf = entr/ entr.sum()\n",
    "\n",
    "\n",
    "nldps = []\n",
    "for i in range(10):\n",
    "    sdps = hs.signals.Signal2D(data_patterns[np.random.choice(np.arange(data_patterns.shape[0]), 5000, True, sl_pdf)])\n",
    "    nldps.append(sdps.data)\n",
    "nlds = flatten_nav(np.asarray(nldps))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_manip_lowq_resized(d, central_box = 256, bs = 256):\n",
    "    pxc, pyc = d.shape[1]//2, d.shape[2]//2 \n",
    "    pxl, pxu = pxc - central_box//2, pxc + central_box//2 \n",
    "    pyl, pyu = pyc - central_box//2, pyc + central_box//2 \n",
    "\n",
    "    d = d[:, pxl:pxu, pyl:pyu]\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    print('resized')\n",
    "    d = d.astype('float32')\n",
    "    for i in range(d.shape[0]):\n",
    "        d_max = np.max(d[i])\n",
    "        d[i] = d[i]/d_max\n",
    "    d = batch_resize(d, bs)\n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "\n",
    "input_data = data_manip_lowq_resized(nlds)\n",
    "#np.random.shuffle(input_data)\n",
    "#input_targets = data_manip_lowq(nlds)\n",
    "val_data = data_manip_lowq_resized(nlds[::10])\n",
    "np.random.shuffle(val_data)\n",
    "\n",
    "\n",
    "\n",
    "##### Otherwise just skip\n",
    "\n",
    "print(input_data.shape)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "train_gen = Array_Generator(input_data, batch_size)#, target = input_targets)\n",
    "valid_gen = Array_Generator(val_data, batch_size)\n",
    "\n",
    "batch_shape = train_gen[0][0].shape\n",
    "input_shape = (batch_shape[1],batch_shape[2],batch_shape[3])\n",
    "out_dims = int(train_gen[0][1].shape[1])\n",
    "\n",
    "### Check the training data\n",
    "\n",
    "rand_patt = np.random.randint(0, len(input_data))\n",
    "\n",
    "### Set the checkpointing\n",
    "\n",
    "chkpoint_filepath = str(mp)+'/chk-{'{epoch:02d}'}-{'{val_loss:.5e}'}.hdf5'\n",
    "chkpoint_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = chkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    "    options=None)\n",
    "\n",
    "### Redefine the model parameters if you want\n",
    "\n",
    "rebin_factor = 1\n",
    "\n",
    "sample_name = 'full'\n",
    "hparams= {model_params}\n",
    "\n",
    "vae_model = create_vae_model(hparams)\n",
    "info[sample_name] = {\"{'rebin': rebin_factor, 'hparams':hparams}\"}\n",
    "\n",
    "vae_model = transfer_layer_weights(gen_model, vae_model, enc_layer_list, dec_layer_list)\n",
    "\n",
    "### Train the Model\n",
    "\n",
    "history = vae_model.fit(train_gen, validation_data=valid_gen, epochs={epochs}, callbacks= [chkpoint_model])\n",
    "\n",
    "cps = mp.walk('.hdf5')\n",
    "best_model_ind = np.asarray([float(str(i).split('-')[-1].split('.hd')[0]) for i in cps]).argmin()\n",
    "best_model = cps[best_model_ind]\n",
    "\n",
    "for x, mod in enumerate(cps):\n",
    "    if x != best_model_ind:\n",
    "        mod.unlink()\n",
    "print('cleared')\n",
    "\n",
    "'''\n",
    "\n",
    "def job_submission_script(fpath):\n",
    "    return f'''\n",
    "#!/bin/bash\n",
    "#$ -l h_rt=119:00:00\n",
    "#$ -cwd\n",
    "#$ -P e02\n",
    "#$ -q all.q\n",
    "#$ -l m_mem_free=128G\n",
    "#$ -l gpu=4\n",
    "\n",
    "\n",
    "module load python/epsic3.7\n",
    "module load cuda/10.1\n",
    "python {fpath}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d85e61",
   "metadata": {},
   "source": [
    "Now we need to create a list of file paths for the datasets you want to train on.\n",
    "You can do this however you like - I like to use this walk function within a list comprehension, using the \"if\" to exclude things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da37425",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp = Path('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/mg28034-1/processing/Merlin/Calibrated/O3_pure')\n",
    "\n",
    "dps = [dp for dp in fdp.walk('.hdf5','binned', max_depth =1) if len(dp.parent.walk('FullModel', max_depth =3)) ==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075a89c",
   "metadata": {},
   "source": [
    "Also need to point to a model to use for the Conv Layer Transfer. Will need the model weights and the params for the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876927f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model_weights = Path('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/mg28034-1/processing/Merlin/Calibrated/GeneralModels/O3_pure/general_model_weights.hdf5')\n",
    "gen_model_params_path = Path('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/mg28034-1/processing/Merlin/Calibrated/GeneralModels/O3_pure/general_model_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f77c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'full': {'rebin': 1, 'hparams': {'KN1': 32, 'KN2': 64, 'KN3': 128, 'KN4': 128, 'KN5': 256, 'D1': 128, 'D2': 512, 'LAT': 128, 'LR': 0.0001, 'B': 1}}}\n"
     ]
    }
   ],
   "source": [
    "with open(gen_model_params_path, 'r') as f:\n",
    "    info = json.load(f)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0783bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KN1': 32, 'KN2': 64, 'KN3': 128, 'KN4': 128, 'KN5': 256, 'D1': 128, 'D2': 512, 'LAT': 128, 'LR': 0.0001, 'B': 1}\n"
     ]
    }
   ],
   "source": [
    "gen_model_params = info['full']['hparams']\n",
    "print(gen_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023e4bd",
   "metadata": {},
   "source": [
    "Finally need to define the model parameters for the model that is being trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e89382",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {'KN1':32,'KN2':64,'KN3':128, 'KN4':128, 'KN5':256,'D1':128,'D2':512,'LAT':2,'LR':0.0001, 'B':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9f022",
   "metadata": {},
   "source": [
    "Finally define the directory to save these to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be32fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = Path('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/ClusterJobs/LoopedTrainingScripts/mg28034/O3_pure/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c772952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp in dps:\n",
    "    timestamp = dp.parts[-2].replace(' ', '_')\n",
    "    \n",
    "    #Get our script and where we are going to save it \n",
    "\n",
    "    example_script = get_script_text(dp, hparams, gen_model_weights, gen_model_params, epochs = 2000)\n",
    "    script_py_path = script_path.redirect(f'{timestamp}_train.py', 0)\n",
    "    \n",
    "    #Get our submission script and where we are going to save that \n",
    "    \n",
    "    script_sub_path = script_py_path.redirect(f'sub_job_{timestamp}.sh')\n",
    "    script_sub = job_submission_script(script_py_path)\n",
    "    \n",
    "    #Save these scripts \n",
    "    \n",
    "    with open(script_py_path, 'w') as f:\n",
    "        f.write(example_script)\n",
    "\n",
    "    with open(script_sub_path, 'w') as f:\n",
    "        f.write(script_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb153bc",
   "metadata": {},
   "source": [
    "Now submit the jobs to hamilton by running the following commands:\n",
    "> module load hamilton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f4cc7",
   "metadata": {},
   "source": [
    "> for f in ./*.sh; do qsub $f; done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.7-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
