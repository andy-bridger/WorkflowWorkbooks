{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05dc8d73",
   "metadata": {},
   "source": [
    "# Generate all the consistency maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd8cfe",
   "metadata": {},
   "source": [
    "### First run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13963caa",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "#load some packages in\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "from numba import njit\n",
    "import hyperspy.api as hs\n",
    "import json\n",
    "import itertools\n",
    "from skimage.metrics import structural_similarity as SSI\n",
    "from stemutils.io import Path\n",
    "import palettable\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1751c7",
   "metadata": {},
   "source": [
    "define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab2c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_label_df(map1):\n",
    "    return np.asarray([np.where(map1 == uinds, 1, 0) for uinds in np.unique(map1)])\n",
    "\n",
    "def get_cluster_label_overlap(map_pair):\n",
    "    '''\n",
    "    Takes a pair of sets of domain binary decompositions \n",
    "    \n",
    "    Looks at each of the N binary decomp in set 1 and compares it to each of the M in set 2 \n",
    "    and works out the number of shared pixels\n",
    "    \n",
    "    Returns the proportion of overlap between each label in 1 with each label in 2 as returns these as a NxM array\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    db1_df,db2_df = map_pair\n",
    "    label_overlap = np.zeros((db1_df.shape[0], db2_df.shape[0]))\n",
    "    for i, idf in enumerate(db1_df):\n",
    "        for j, jdf in enumerate(db2_df):\n",
    "            label_overlap[i,j] = np.sum(db1_df[i] * db2_df[j])/ np.sum(db1_df[i])\n",
    "    return label_overlap\n",
    "\n",
    "def find_map_label(pos, map1):\n",
    "    return map1[pos]\n",
    "\n",
    "def get_confidence_from_maps(maps):\n",
    "    dfs = [x for x in map(get_map_label_df, maps)] #get a list of lists of domain regions\n",
    "    map1 = maps[0]\n",
    "    \n",
    "    #for each pair of maps get the cluster overlap proportion arrays\n",
    "    cluster_overlaps = [x for x in map(get_cluster_label_overlap, [x for x in itertools.permutations(dfs, 2)])]\n",
    "\n",
    "    #get all the permutations of pairs of maps in index form\n",
    "    overlap_inds = [x for x in itertools.permutations(np.arange(len(maps)), 2)]\n",
    "\n",
    "    len(cluster_overlaps)\n",
    "\n",
    "    confidence = np.zeros_like(map1, dtype='float32')\n",
    "    for point in range(len(map1)):\n",
    "        #get a list of labels for each row of each map\n",
    "        labels = [i for i in map(find_map_label, np.repeat(point, len(maps)) , maps)]\n",
    "        total = 0\n",
    "        for cind, oinds in enumerate(overlap_inds):\n",
    "            #for each pair of map comparisons get the labels for this row\n",
    "            l1, l2 = labels[oinds[0]], labels[oinds[1]]\n",
    "            total+=cluster_overlaps[cind][l1, l2]\n",
    "        mean = total/len(overlap_inds)\n",
    "        confidence[point] = mean\n",
    "    return confidence\n",
    "\n",
    "def flatten_nav(sig):\n",
    "    shape = [sig.shape[0]*sig.shape[1]]\n",
    "    for i in sig.shape[2:]:\n",
    "        shape.append(i)\n",
    "    return sig.reshape(shape)\n",
    "\n",
    "\n",
    "def plot_map_confs(gtmap, conf, save_root = None, **kwargs):\n",
    "    mean_class_ssi = []\n",
    "    conf_r, r_patts = [],[]\n",
    "    for uind in np.unique(gtmap):\n",
    "        rconf = np.round((np.where(gtmap == uind,1,0) * conf),1)\n",
    "        frconf = flatten_nav(rconf.copy())\n",
    "        patterns = []\n",
    "        for confind in np.unique(frconf):\n",
    "            if confind != 0:\n",
    "                patterns.append(frd[np.where(frconf == confind)].mean(axis = 0))\n",
    "        patterns = np.asarray(patterns)\n",
    "\n",
    "        if patterns.shape[0] > 1:\n",
    "            \n",
    "            conf_r.append(rconf)\n",
    "            r_patts.append(patterns)\n",
    "\n",
    "            p_comb = [inds for inds in itertools.combinations(list(range(patterns.shape[0])),2)]\n",
    "\n",
    "            class_ssi = np.mean([SSI(patterns[p_c[0]], patterns[p_c[1]]) for p_c in p_comb])\n",
    "            mean_class_ssi.append(class_ssi)\n",
    "\n",
    "            pgs = int(np.ceil(np.sqrt(patterns.shape[0])))\n",
    "\n",
    "            fig = plt.figure()\n",
    "            gs = GridSpec(pgs*2, pgs, figure = fig)\n",
    "            ax0 = fig.add_subplot(gs[:pgs,:])\n",
    "            ax0.imshow(rconf, cmap= cmap, interpolation = 'nearest')\n",
    "            ax0.set_xticks([])\n",
    "            ax0.set_yticks([])\n",
    "            ax0.set_title(str(class_ssi))\n",
    "            for ipatt, patt in enumerate(patterns):\n",
    "                gsx = ipatt//pgs\n",
    "                gsy = ipatt%pgs\n",
    "                axp = fig.add_subplot(gs[pgs+gsx,gsy])\n",
    "                axp.imshow(patt, cmap = 'gray', **kwargs)\n",
    "                axp.set_xticks([])\n",
    "                axp.set_yticks([])\n",
    "            if save_root != None:\n",
    "                fig.savefig(f'{save_root}/{uind}-conf_regions.jpg')\n",
    "    return conf_r, r_patts\n",
    "\n",
    "def eval_map_conf(gtmap, conf):\n",
    "    mean_class_ssi = []\n",
    "    for uind in np.unique(gtmap):\n",
    "        rconf = np.round((np.where(gtmap == uind,1,0) * conf),1)\n",
    "        frconf = flatten_nav(rconf)\n",
    "        patterns = []\n",
    "        for confind in np.unique(frconf):\n",
    "            if confind != 0:\n",
    "                patterns.append(frd[np.where(frconf == confind)].max(axis = 0))\n",
    "        patterns = np.asarray(patterns)\n",
    "\n",
    "        if patterns.shape[0] > 1:\n",
    "\n",
    "            p_comb = [inds for inds in itertools.combinations(list(range(patterns.shape[0])),2)]\n",
    "\n",
    "            class_ssi = np.mean([SSI(patterns[p_c[0]], patterns[p_c[1]]) for p_c in p_comb])\n",
    "            mean_class_ssi.append(class_ssi)\n",
    "        else:\n",
    "            mean_class_ssi.append(1.0)\n",
    "\n",
    "    return np.mean(mean_class_ssi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea825197",
   "metadata": {},
   "source": [
    "Generate a list (dss) of all the datasets you want to generate the consistency maps for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4715313",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_root = Path('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/mg28034-1/processing/Merlin/Calibrated/O3_pure/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = [ds for ds in ds_root.ls() if str(ds.parts[-1]).replace(' ','').isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10050362",
   "metadata": {},
   "source": [
    "First Test the workflow on a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in dss[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b0c73",
   "metadata": {},
   "source": [
    "Find all the map files that you want to use to generate the consistency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_maps_root = ds.redirect('Refined_N_components',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12816c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_map_paths = domain_maps_root.walk('/mapdata', max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_map_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c417c6",
   "metadata": {},
   "source": [
    "Find the path to the raw data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = ds.walk(f\"{ds.parts[-1].split(' ')[-1]}.hdf5\",'binned', max_depth=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756303c8",
   "metadata": {},
   "source": [
    "Load in all the maps and then generate the confidence map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4410e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = [np.load(p, allow_pickle=True).astype('int8') for p in domain_map_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded22ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_confidence_from_maps(maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243768cb",
   "metadata": {},
   "source": [
    "Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given colormap which takes values from 0→50\n",
    "colors1 = palettable.colorbrewer.sequential.YlGn_9.mpl_colormap(np.linspace(0, 1, 256))\n",
    "colors1[0] = [0.,0.,0.,1.]\n",
    "# generating a smoothly-varying LinearSegmentedColormap\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list('colormap', colors1)\n",
    "\n",
    "conf_fig = plt.figure(figsize = (8,8))\n",
    "plt.imshow(conf, cmap= cmap, interpolation = 'nearest', vmin=0, vmax =1 )\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276ffad",
   "metadata": {},
   "source": [
    "Save to a desired path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_maps_root.redirect('consistency_map.jpg',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_fig.savefig(domain_maps_root.redirect('consistency_map.jpg',0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73c12f",
   "metadata": {},
   "source": [
    "Load in the diffraction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hs.load(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe0c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frd = flatten_nav(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7936b",
   "metadata": {},
   "source": [
    "Find all the map directories and for each one visualise and save the consistency regions within each map region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomps = [int(x.parts[-1]) for x in domain_map_paths[0].redirect('',2).ls() if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a942ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ncomp in ncomps:\n",
    "    print(ncomp)\n",
    "    comp_dir = domain_maps_root.redirect(f'{ncomp}/',0)\n",
    "    gtmap = np.load(comp_dir.redirect('mapdata.npy',0))\n",
    "    consistency_dir = comp_dir.redirect('ConsistencyRegions',0)\n",
    "    consistency_dir.mk()\n",
    "    conf_r, r_patts = plot_map_confs(gtmap,conf, save_root= consistency_dir, vmax = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9890b",
   "metadata": {},
   "source": [
    "If that has all worked fine, repeat in a loop for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50674657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in dss[3:]:\n",
    "\n",
    "    domain_maps_root = ds.redirect('Refined_N_components',0)\n",
    "\n",
    "    domain_map_paths = domain_maps_root.walk('/mapdata', max_depth=2)\n",
    "\n",
    "    domain_map_paths\n",
    "\n",
    "    dp = ds.walk(f\"{ds.parts[-1].split(' ')[-1]}.hdf5\",'binned', max_depth=1)[0]\n",
    "\n",
    "    dp\n",
    "\n",
    "    maps = [np.load(p, allow_pickle=True).astype('int8') for p in domain_map_paths]\n",
    "\n",
    "    conf = get_confidence_from_maps(maps)\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    colors1 = palettable.colorbrewer.sequential.YlGn_9.mpl_colormap(np.linspace(0, 1, 256))\n",
    "    colors1[0] = [0.,0.,0.,1.]\n",
    "    # generating a smoothly-varying LinearSegmentedColormap\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list('colormap', colors1)\n",
    "\n",
    "\n",
    "    conf_fig = plt.figure(figsize = (8,8))\n",
    "    plt.imshow(conf, cmap= cmap, interpolation = 'nearest', vmin=0, vmax =1 )\n",
    "    plt.colorbar()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    conf_fig.savefig(domain_maps_root.redirect('consistency_map.jpg',0))\n",
    "\n",
    "    data = hs.load(dp)\n",
    "\n",
    "    frd = flatten_nav(data.data)\n",
    "\n",
    "    data.data.shape[0]\n",
    "\n",
    "    ncomps = [int(x.parts[-1]) for x in domain_map_paths[0].redirect('',2).ls() if x.is_dir()]\n",
    "\n",
    "    for ncomp in ncomps:\n",
    "        print(ncomp)\n",
    "        comp_dir = domain_maps_root.redirect(f'{ncomp}/',0)\n",
    "        gtmap = np.load(comp_dir.redirect('mapdata.npy',0))\n",
    "        consistency_dir = comp_dir.redirect('ConsistencyRegions',0)\n",
    "        consistency_dir.mk()\n",
    "        conf_r, r_patts = plot_map_confs(gtmap,conf, save_root= consistency_dir, vmax = 3)\n",
    "\n",
    "    plt.close('all')\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26080b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.7-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
